{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Memorability C3D and Captions Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "bgyKWq9Q-w9T",
        "Rk9By_oD-8Ih",
        "rQM_pxEl-7xe",
        "xogEPNCp-7mk",
        "Fyfz4p-dPq8a",
        "VfqN36dFv9nn"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "NwnJIOIm-M4Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Predicting Memorability\n",
        "\n",
        "In this notebook I have combined the videos captions and C3D features to predict video memorability and run them through an XGboost regressor model"
      ]
    },
    {
      "metadata": {
        "id": "bgyKWq9Q-w9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1. Set up and Libraries"
      ]
    },
    {
      "metadata": {
        "id": "DmFgOkN9_jaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive   #Mount Google drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/Machine Learning/Project/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KV2tbcwH_mKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pyprind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2jPplmFj_uOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import panda and other libraries required\n",
        "\n",
        "import pandas as pd\n",
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "import pyprind\n",
        "from collections import Counter\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import preprocessing\n",
        "import os\n",
        "\n",
        "#Randomising for reproducability\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mlPznEfQ_fum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Get_score(Y_pred,Y_true):    #Spearman function\n",
        "    '''Calculate the Spearmann\"s correlation coefficient'''\n",
        "    Y_pred = np.squeeze(Y_pred)\n",
        "    Y_true = np.squeeze(Y_true)\n",
        "    if Y_pred.shape != Y_true.shape:\n",
        "        print('Input shapes don\\'t match!')\n",
        "    else:\n",
        "        if len(Y_pred.shape) == 1:\n",
        "            Res = pd.DataFrame({'Y_true':Y_true,'Y_pred':Y_pred})\n",
        "            score_mat = Res[['Y_true','Y_pred']].corr(method='spearman',min_periods=1)\n",
        "            print('The Spearman\\'s correlation coefficient is: %.3f' % score_mat.iloc[1][0])\n",
        "        else:\n",
        "            for ii in range(Y_pred.shape[1]):\n",
        "                Get_score(Y_pred[:,ii],Y_true[:,ii])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x84i5PlXcMcz",
        "colab_type": "code",
        "outputId": "077bbd45-1ada-49b5-abb0-7d47dcd70455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install xgboost  #xgboost model and the libraries needed for it below\n",
        "\n",
        "from numpy import loadtxt   \n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import ensemble"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rk9By_oD-8Ih",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2. Captions"
      ]
    },
    {
      "metadata": {
        "id": "l1WbM-FGBM4O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading Captions"
      ]
    },
    {
      "metadata": {
        "id": "M21XkbZCBAjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load labels and captions \n",
        "def read_caps(fname):\n",
        "    \"\"\"Load the captions into a dataframe\"\"\"\n",
        "    vn = []\n",
        "    cap = []\n",
        "    df = pd.DataFrame();\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            pairs = line.split()\n",
        "            vn.append(pairs[0])\n",
        "            cap.append(pairs[1])\n",
        "        df['video']=vn\n",
        "        df['caption']=cap\n",
        "    return df\n",
        "\n",
        "\n",
        "# load the captions txt file\n",
        "cap_path = './dev-set_video-captions.txt'\n",
        "df_cap=read_caps(cap_path)\n",
        "\n",
        "# load the ground truth values from csv file\n",
        "label_path = './'\n",
        "labels=pd.read_csv(label_path+'dev-set_ground-truth.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U03ao3MaBAca",
        "colab_type": "code",
        "outputId": "0bc7a8c5-5a21-45e8-bb0c-afcc6af6a05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "counts = Counter()\n",
        "# setup prograss tracker\n",
        "pbar = pyprind.ProgBar(len(df_cap['caption']), title='Counting word occurrences')\n",
        "for i, cap in enumerate(df_cap['caption']):\n",
        "    # replace punctuations with space\n",
        "    # convert words to lower case \n",
        "    text = ''.join([c if c not in punctuation else ' ' for c in cap]).lower()\n",
        "    df_cap.loc[i,'caption'] = text\n",
        "    pbar.update()\n",
        "    counts.update(text.split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting word occurrences\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:04\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTGWXpZ_BO7F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocessing Captions"
      ]
    },
    {
      "metadata": {
        "id": "zblNmNgjBAUw",
        "colab_type": "code",
        "outputId": "4e00061f-afab-4667-8531-c99e7caf2383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# build the word index\n",
        "len_token = len(counts)\n",
        "tokenizer = Tokenizer(num_words=len_token)\n",
        "print(len_token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xcO6peJhBAMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(list(df_cap.caption.values)) #fit a list of captions to the tokenizer\n",
        "#the tokenizer vectorizes a text corpus, by turning each text into either a sequence of integers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxaZntU2BADk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_hot_res = tokenizer.texts_to_matrix(list(df_cap.caption.values),mode='binary')\n",
        "sequences = tokenizer.texts_to_sequences(list(df_cap.caption.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOu3Co4yBbJP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculating max length\n",
        "max_len = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqOz7QuzBbDf",
        "colab_type": "code",
        "outputId": "0d9bdc87-cb61-427d-e030-d6df77062392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_seq = np.zeros((len(sequences),max_len))  #creating sequences of tokenized captions (6000 rows of 50 columns, padded with zeros when cpations are not of length 50)\n",
        "for i in range(len(sequences)):\n",
        "    n = len(sequences[i])\n",
        "    if n==0:\n",
        "        print(i)\n",
        "    else:\n",
        "        X_seq[i,-n:] = sequences[i]\n",
        "X_seq.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "x-zsEg4DBbBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_seq = pd.DataFrame(X_seq)    #create dataframe with the sequences\n",
        "df_seq = pd.concat([df_cap, df_seq], axis = 1)   #merging sequnces dataframe and the captions dataframe to I can line up video name to each sequence\n",
        "df_seq = df_seq.drop(\"caption\", axis=1)  #removing column with word version of caption so we have a dataframe where the integer sequences are algined with the primary key (video names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZSBQrFMhDxlR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_seq)  #final dataframe for captions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQM_pxEl-7xe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##3. C3D"
      ]
    },
    {
      "metadata": {
        "id": "QSJgrRcyBB2A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_C3D(fname):   #function to read c3d vectors into dataframe\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            C3D =[float(item) for item in line.split()] # convert to float type, using default separator\n",
        "    return C3D\n",
        "\n",
        "def vname2ID(vnames):  #function to read video name and format correclty for dataframe, which will be used as primary key to merge sequences dataframe and c3d dataframe\n",
        "    vid = [ os.path.splitext(vn)[0]+'.webm' for vn in vnames]\n",
        "    return vid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQy_AA88BBze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Feat_path = './Features/'    #creates file path to my features directory in drive\n",
        "\n",
        "vid = labels.video.values  #pull in video labels first\n",
        "\n",
        "c3d_features = pd.DataFrame({'video': vid,\n",
        "                   'C3D': [read_C3D(Feat_path+'C3D'+'/'+os.path.splitext(item)[0]+'.txt') for item in vid],\n",
        "                       }) #pulls c3d vectors from c3d feature txt file.\n",
        "#This extraction to a dataframe takes quite awhile to run (15/20 minutes). \n",
        "#It usually fails the first 2 or 3 times on my device but works eventually. I believe this is due to processing power"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xQ_Ut0ML4u2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(c3d_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vwyk3zYjCWA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Splitting C3D values out into individual columns"
      ]
    },
    {
      "metadata": {
        "id": "Hg7GTauZCexr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features1 = pd.DataFrame(c3d_features.C3D.apply(pd.Series))  #split out c3d column into individual rows\n",
        "features2 = pd.concat([c3d_features, features1], axis = 1)  #merges features and features1 (splits out into columns)\n",
        "features2 = features2.drop(\"C3D\", axis=1)    #drops column where all c3d features are combined in 1 column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xogEPNCp-7mk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##4. Combining Dataframes "
      ]
    },
    {
      "metadata": {
        "id": "gmEJdtFqCRTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_x = pd.merge(df_seq, features2, on='video')  #merging captions sequences dataframe to ce3 features dataframe on the column video"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TidKZhtmCRH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_x = df_x.drop('video', axis = 1)  #drop video column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8w1p6GlbCQ3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fyfz4p-dPq8a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##5. Test Data"
      ]
    },
    {
      "metadata": {
        "id": "yYLto4tigNFG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pulling test data"
      ]
    },
    {
      "metadata": {
        "id": "ulO7hEdqSTwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the test captions txt file\n",
        "test_cap_path = './Test/test-set-1_video-captions.txt'\n",
        "df_test_cap=read_caps(test_cap_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSKRbxMLSnr7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_test_cap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pUicjpO4Pxc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load testing data - this should load in test set of videos (again this can take around 10 mins to run)\n",
        "test_path = './Test/'\n",
        "#test_vid = os.listdir(test_path+'C3D_test')\n",
        "\n",
        "vid = df_test_cap.video.values  #pull in video labels first\n",
        "\n",
        "Features_test = pd.DataFrame({'video': vid,\n",
        "                   'C3D': [read_C3D(test_path+'C3D_test'+'/'+os.path.splitext(item)[0]+'.txt') for item in vid],\n",
        "                       })\n",
        "\n",
        "#Features_test = pd.DataFrame({'video': test_vid,\n",
        "                   #'C3D': [read_C3D(test_path+'C3D_test'+'/'+item) for item in test_vid],\n",
        "                    #   })\n",
        "X_test = np.stack(Features_test['C3D'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCqSZgWbgAjk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(Features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imQUYJiXgQjl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pre-processing test caption data to mirror dev data"
      ]
    },
    {
      "metadata": {
        "id": "8ko5H4S8PxPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counts = Counter()\n",
        "# setup prograss tracker\n",
        "pbar = pyprind.ProgBar(len(df_test_cap['caption']), title='Counting word occurrences')\n",
        "for i, cap in enumerate(df_test_cap['caption']):\n",
        "    # replace punctuations with space\n",
        "    # convert words to lower case \n",
        "    text = ''.join([c if c not in punctuation else ' ' for c in cap]).lower()\n",
        "    df_test_cap.loc[i,'caption'] = text\n",
        "    pbar.update()\n",
        "    counts.update(text.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtCo4mGDPxGa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build the word index\n",
        "len_token = len(counts)\n",
        "tokenizer = Tokenizer(num_words=len_token)\n",
        "print(len_token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vm5O6ITPPw9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(list(df_test_cap.caption.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWRC8AyjPw2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_hot_res = tokenizer.texts_to_matrix(list(df_test_cap.caption.values),mode='binary')\n",
        "test_sequences = tokenizer.texts_to_sequences(list(df_test_cap.caption.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKS_jmBtPwtp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_seq = np.zeros((len(test_sequences),max_len))\n",
        "for i in range(len(test_sequences)):\n",
        "    n = len(test_sequences[i])\n",
        "    if n==0:\n",
        "        print(i)\n",
        "    else:\n",
        "        X_test_seq[i,-n:] = test_sequences[i]\n",
        "X_test_seq.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HStZPsHUPwkj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_seq = pd.DataFrame(X_test_seq)    #create dataframe with the sequences\n",
        "df_test_seq = pd.concat([df_test_cap, df_test_seq], axis = 1)   #merging sequnces dataframe and the captions dataframe to I can line up video name to each sequence\n",
        "df_test_seq = df_test_seq.drop(\"caption\", axis=1)  #removing column with word version of caption so we have a dataframe where the integer sequences are algined with the primary key (video names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "he8aV8A-m-on",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_test_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GEtGTuiDnOYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pre-processing test c3d data to mirror dev"
      ]
    },
    {
      "metadata": {
        "id": "vDq2Vi5vnIGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Features_test1 = pd.DataFrame(Features_test.C3D.apply(pd.Series))  #split out c3d column into individual rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pNzlS_m_nPgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(Features_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-k8N9JZnPcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Features_test2 = pd.concat([Features_test, Features_test1], axis = 1)  #merges features and features1 (splits out into columns)\n",
        "Features_test2 = Features_test2.drop(\"C3D\", axis=1)    #drops column where all c3d features are combined in 1 column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlw5o_hHn6yr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(Features_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GFpBri-oyxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Merging test captions sequences and test c3d features"
      ]
    },
    {
      "metadata": {
        "id": "8nePpfNjox_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_x = pd.merge(df_test_seq, Features_test2, on='video')\n",
        "df_test_x = df_test_x.drop('video', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-bUKcWjpLF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXZMLYTyUBq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##6. Training Model using Gradient Boosting Regressor"
      ]
    },
    {
      "metadata": {
        "id": "SBdOYb0Ufb3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_st = labels['short-term_memorability'].values # st targets\n",
        "Y_lt = labels['long-term_memorability'].values  # lt targets\n",
        "X = df_x.values # sequences & C3D merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "egMo8Aa7nXrv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_st, X_test_st, Y_train_st, Y_test_st = train_test_split(X,Y_st, test_size=0.2, random_state=42) \n",
        "#splitting the short term dev data into a train and validate split of 80 to 20 with a random state for reproducability\n",
        "\n",
        "X_train_lt, X_test_lt, Y_train_lt, Y_test_lt = train_test_split(X,Y_lt, test_size=0.2, random_state=42) \n",
        "# #splitting the long term dev data into a train and validate split of 80 to 20 with a random state for reproducability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTypgV2-_3t6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "R1-MmQsEnbcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Just testing to see shape of data split for Short Term\n",
        "print('X_train', X_train_st.shape)\n",
        "print('X_test', X_test_st.shape)\n",
        "print('Y_train', Y_train_st.shape)\n",
        "print('Y_test', Y_test_st.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dOhWugRtY_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Just testing to see shape of data split for Long Term\n",
        "print('X_train', X_train_lt.shape)\n",
        "print('X_test', X_test_lt.shape)\n",
        "print('Y_train', Y_train_lt.shape)\n",
        "print('Y_test', Y_test_lt.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgKFlduUT_yu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Params - 650 decision tree, 12 depth, learning rate 0.01\n",
        "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
        "clf = ensemble.GradientBoostingRegressor(**params)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMNu2OJ_fxpP",
        "colab_type": "code",
        "outputId": "d52d65cd-bfe2-4df0-ecf8-831e68be0bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#fit to short term training set\n",
        "clf.fit(X_train_st, Y_train_st)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "             learning_rate=0.01, loss='lad', max_depth=12,\n",
              "             max_features=None, max_leaf_nodes=None,\n",
              "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "             min_samples_leaf=1, min_samples_split=2,\n",
              "             min_weight_fraction_leaf=0.0, n_estimators=650,\n",
              "             n_iter_no_change=None, presort='auto', random_state=None,\n",
              "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "nMipnywSt8Bp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#predict for stm for test set\n",
        "print('Short Term:')\n",
        "print(Get_score(clf.predict(X_test_st), Y_test_st))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fcJxM4SHtrkh",
        "colab_type": "code",
        "outputId": "0e1d54aa-4e53-4198-de0f-5c5dc8045604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#fit to training set\n",
        "clf.fit(X_train_lt, Y_train_lt)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "             learning_rate=0.01, loss='lad', max_depth=12,\n",
              "             max_features=None, max_leaf_nodes=None,\n",
              "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "             min_samples_leaf=1, min_samples_split=2,\n",
              "             min_weight_fraction_leaf=0.0, n_estimators=650,\n",
              "             n_iter_no_change=None, presort='auto', random_state=None,\n",
              "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "LkG7_ZynfxZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#predict for ltm for test set\n",
        "print('Long Term:')\n",
        "print(Get_score(clf.predict(X_test_lt), Y_test_lt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7b6hq4LQ1S-T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = pd.DataFrame(clf.predict(X_test_st))\n",
        "a.columns = ['x']\n",
        "b = pd.DataFrame(clf.predict(X_test_lt))\n",
        "b.columns = ['y']\n",
        "\n",
        "\n",
        "ab = pd.concat([a, b], axis=1)\n",
        "\n",
        "print(ab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ll1JVSeD5ABC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Mapping my predictions (on test split of videos) against the trained set for short term\n",
        "\n",
        "#Y_pred_train = model.predict(X_train)\n",
        "Y_pred_train = clf.predict(X_train_st)\n",
        "Y = labels['short-term_memorability'].values\n",
        "Y_train = Y_train_st\n",
        "#Y_pred_val = model.predict(X_val)\n",
        "Y_pred_val = clf.predict(X_test_st)\n",
        "X = df_x.values\n",
        "Y_val = Y_test_st\n",
        "\n",
        "if len(Y.shape) == 2:\n",
        "    plt.figure()\n",
        "    plt.scatter(Y_pred_train[:,0],Y_pred_train[:,1],marker='o',c='r',label='train')\n",
        "    plt.scatter(Y_pred_val[:,0],Y_pred_val[:,1],marker='x',c='g',label='val')\n",
        "    plt.scatter(Y[:,0],Y[:,1],marker='x',c='b',label='true',alpha=0.1)\n",
        "    plt.xlim([0,1])\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend()\n",
        "    plt.xlabel('short-term')\n",
        "    plt.ylabel('long-term')\n",
        "    plt.title('Training results')\n",
        "    plt.show()\n",
        "    \n",
        "    # plot testing results\n",
        "    Y_pred = model.predict(X_test[:,:],batch_size=32)\n",
        "    plt.figure()\n",
        "    plt.scatter(Y_pred[:,0],Y_pred[:,1],marker='o',c='r')\n",
        "    plt.xlabel('short-term')\n",
        "    plt.ylabel('long-term')\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    plt.figure()\n",
        "    plt.scatter(Y_pred_train,Y_train,marker='o',c='r',label='train')\n",
        "    plt.scatter(Y_pred_val,Y_val,marker='x',c='g',label='val')\n",
        "    #plt.scatter(Y[:,0],Y[:,1],marker='x',c='b',label='true',alpha=0.1)\n",
        "    plt.xlim([0,1])\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend()\n",
        "    plt.xlabel('true')\n",
        "    plt.ylabel('pred')\n",
        "    plt.title('Training results [short-term]')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9o6zdrhf6v_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Mapping my predictions (on test split of videos) against the trained set for long term\n",
        "\n",
        "#Y_pred_train = model.predict(X_train)\n",
        "Y_pred_train = clf.predict(X_train_lt)\n",
        "Y = labels['long-term_memorability'].values\n",
        "Y_train = Y_train_lt\n",
        "#Y_pred_val = model.predict(X_val)\n",
        "Y_pred_val = clf.predict(X_test_lt)\n",
        "X = df_x.values\n",
        "Y_val = Y_test_lt\n",
        "\n",
        "if len(Y.shape) == 2:\n",
        "    plt.figure()\n",
        "    plt.scatter(Y_pred_train[:,0],Y_pred_train[:,1],marker='o',c='r',label='train')\n",
        "    plt.scatter(Y_pred_val[:,0],Y_pred_val[:,1],marker='x',c='g',label='val')\n",
        "    plt.scatter(Y[:,0],Y[:,1],marker='x',c='b',label='true',alpha=0.1)\n",
        "    plt.xlim([0,1])\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend()\n",
        "    plt.xlabel('short-term')\n",
        "    plt.ylabel('long-term')\n",
        "    plt.title('Training results')\n",
        "    plt.show()\n",
        "    \n",
        "    # plot testing results\n",
        "    Y_pred = model.predict(X_test[:,:],batch_size=32)\n",
        "    plt.figure()\n",
        "    plt.scatter(Y_pred[:,0],Y_pred[:,1],marker='o',c='r')\n",
        "    plt.xlabel('short-term')\n",
        "    plt.ylabel('long-term')\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    plt.figure()\n",
        "    plt.scatter(Y_pred_train,Y_train,marker='o',c='r',label='train')\n",
        "    plt.scatter(Y_pred_val,Y_val,marker='x',c='g',label='val')\n",
        "    #plt.scatter(Y[:,0],Y[:,1],marker='x',c='b',label='true',alpha=0.1)\n",
        "    plt.xlim([0,1])\n",
        "    plt.ylim([0,1])\n",
        "    plt.legend()\n",
        "    plt.xlabel('true')\n",
        "    plt.ylabel('pred')\n",
        "    plt.title('Training results [Long-term]')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VfqN36dFv9nn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##7. Predictions on Test Data"
      ]
    },
    {
      "metadata": {
        "id": "KZ0CqY_EwTBr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Retrain on all 6000 and then predict versus extra 2000 videos (test set)"
      ]
    },
    {
      "metadata": {
        "id": "hfMHSRjDwin9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_full_train = df_x.values\n",
        "Y_full_train_st = labels['short-term_memorability'].values    \n",
        "Y_full_train_lt = labels['long-term_memorability'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TLJwyPT80l-R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('X_train', X_full_train.shape)\n",
        "print('Y_train lt', Y_full_train_lt.shape)\n",
        "print('Y_train st', Y_full_train_st.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9170Abq-0Ynk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Params\n",
        "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
        "clf_final_st = ensemble.GradientBoostingRegressor(**params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "duCNFvH5xwRR",
        "colab_type": "code",
        "outputId": "2c57b8d8-5001-45b0-b82c-12c55e0b4638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#fit to training set short term\n",
        "clf_final_st.fit(X_full_train, Y_full_train_st)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "             learning_rate=0.01, loss='lad', max_depth=12,\n",
              "             max_features=None, max_leaf_nodes=None,\n",
              "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "             min_samples_leaf=1, min_samples_split=2,\n",
              "             min_weight_fraction_leaf=0.0, n_estimators=650,\n",
              "             n_iter_no_change=None, presort='auto', random_state=None,\n",
              "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "70WWgEV2yZrD",
        "colab_type": "code",
        "outputId": "d7fcc978-2d66-4a6e-9ec4-b8e1c715a1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "prediction_st = clf_final_st.predict(df_test_x)\n",
        "print('long term:')\n",
        "print(prediction_st)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "long term:\n",
            "[0.86469816 0.84926329 0.8906271  ... 0.89554188 0.83799726 0.88480207]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JnUbkIE8Q3FT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Params\n",
        "params = {'n_estimators':650, 'max_depth':12, 'min_samples_split':2, 'learning_rate':0.01, 'loss':'lad'}\n",
        "clf_final_lt = ensemble.GradientBoostingRegressor(**params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BITgx3IV1kwF",
        "colab_type": "code",
        "outputId": "cba0e52a-c575-454d-a710-598ff8c29ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "#fit to training set long term\n",
        "clf_final_lt.fit(X_full_train, Y_full_train_lt)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "             learning_rate=0.01, loss='lad', max_depth=12,\n",
              "             max_features=None, max_leaf_nodes=None,\n",
              "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "             min_samples_leaf=1, min_samples_split=2,\n",
              "             min_weight_fraction_leaf=0.0, n_estimators=650,\n",
              "             n_iter_no_change=None, presort='auto', random_state=None,\n",
              "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "sYbkPdTK1osW",
        "colab_type": "code",
        "outputId": "4d186b17-0b0e-4eb9-9b1a-1067345f1820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#predict test set long term\n",
        "prediction_lt = clf_final_lt.predict(df_test_x)\n",
        "print('short term:')\n",
        "print(prediction_lt)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "short term:\n",
            "[0.81577341 0.71708777 0.79955709 ... 0.8310571  0.7486182  0.80393799]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iJkdO-yILYpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##8. Preparing CSV and Exporting"
      ]
    },
    {
      "metadata": {
        "id": "ozKO-8e_TrCw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating data frames for both st and lt predictions\n",
        "df_predictions_final_st = pd.DataFrame(prediction_st)\n",
        "df_predictions_final_st.columns = ['short-term_memorability']\n",
        "df_predictions_final_lt = pd.DataFrame(prediction_lt)\n",
        "df_predictions_final_lt.columns = ['long-term_memorability']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvc2wdCjT5n1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_predictions_final_st)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-lrCO48T8u1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_predictions_final_lt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ur9_KvksLWFW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "my_predictions_st = pd.concat([df_test_cap, df_predictions_final_st], axis = 1)  #merges predictions st to captions\n",
        "my_predictions_st = my_predictions_st.drop(\"caption\", axis=1)    #drop captions row"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKGqA87LM1Fq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(my_predictions_st)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gLcvxK9TMciM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "my_predictions_lt = pd.concat([df_test_cap, df_predictions_final_lt], axis = 1)  #merges predictions st to captions\n",
        "my_predictions_lt = my_predictions_lt.drop(\"caption\", axis=1)    #drop captions row"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qjhfzy5cM0hl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(my_predictions_lt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXMsBrVjULu3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_predictions_final = pd.merge(my_predictions_st, my_predictions_lt, on='video')\n",
        "df_predictions_final = df_predictions_final.drop(\"video\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rxryzzZjUnky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(df_predictions_final)    #Here is the data frame containing my short term and long term prediction having dropped the video column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRWC_AadW8TN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "template_path = './' #set path to current directory\n",
        "template=pd.read_csv(label_path+'Copy of ground_truth_template.csv')  #pulls in csv file from google drive and store in template\n",
        "template1 = pd.DataFrame(template)  #create data frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R94DZHM2ZKUc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(template1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g7BsxqLgEw7F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ground_truth_values = template1.drop('short-term_memorability', axis=1)   #drop short term memorability row\n",
        "ground_truth_values = ground_truth_values.drop('long-term_memorability', axis=1)   #drop long term memorability row\n",
        "\n",
        "\n",
        "ground_truth_values = pd.concat([ground_truth_values, df_predictions_final], axis = 1)   #merge with my final predictions\n",
        "\n",
        "ground_truth_values = ground_truth_values[['video', 'short-term_memorability','nb_short-term_annotations','long-term_memorability', 'nb_long-term_annotations']]  #rearrange columns to right order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cz3_QE9PXe_F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(ground_truth_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAjSKeky5QAe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ground_truth_values.to_csv('ground_truth_values.csv')\n",
        "!cp ground_truth_values.csv csv/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}